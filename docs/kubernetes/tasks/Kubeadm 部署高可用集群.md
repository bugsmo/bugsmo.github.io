---
order: 1
tags:
  - k8så®‰è£…
title: Kubeadm éƒ¨ç½²é«˜å¯ç”¨é›†ç¾¤
date: 2023-10-19 14:21:49
categories:
  - kubernetes
  - tasks
columns:
  -
---

# Kubeadm éƒ¨ç½²é«˜å¯ç”¨é›†ç¾¤

## 1. ä¸»æœºé…ç½®

é¢„å®‰è£… CentOS7ã€‚

### 1.1 è®¾ç½®æ—¶é—´

å¼€å¯æ—¶é—´åŒæ­¥

```bash
yum install -y chrony

systemctl enable chronyd

systemctl start chronyd

systemctl status chronyd

timedatectl set-ntp true

timedatectl status
```

::: warning
Warning: The system is configured to read the RTC time in the local time zone.
This mode can not be fully supported. It will create various problems
with time zone changes and daylight saving time adjustments. The RTC
time is never updated, it relies on external facilities to maintain it.
If at all possible, use RTC in UTC by calling
'timedatectl set-local-rtc 0'.
:::

æ— ç‰¹æ®Šæƒ…å†µï¼Œä¸èƒ½å¯ç”¨ç¡¬ä»¶çš„æ—¶é’Ÿæ¥æ ¡æ—¶ã€‚

```bash
timedatectl set-local-rtc 0
```

è®¾ç½®æ—¶åŒº

```bash
timedatectl set-timezone Asia/Shanghai
```

æ£€æŸ¥ ntp-server æ˜¯å¦å¯ç”¨

```bash
chronyc activity -v
```

### 1.2 è®¾ç½®é˜²ç«å¢™

å…³é—­æ‰€æœ‰é˜²ç«å¢™ã€‚

```bash
iptables -F

systemctl status firewalld

systemctl stop firewalld

systemctl disable firewalld
```

### 1.3 é™æ€ host

æ‰€æœ‰è®¡åˆ’åŠ å…¥ k8s é›†ç¾¤çš„æœºå™¨ã€‚

```bash
cat /etc/hosts

172.16.0.175 free00
172.16.0.167 free01
172.16.0.168 free02
172.16.0.170 free03
```

### 1.4 æ£€æŸ¥ mac å’Œ product_uuid

åŒä¸€ä¸ª k8s é›†ç¾¤å†…çš„æ‰€æœ‰èŠ‚ç‚¹éœ€è¦ç¡®ä¿ mac åœ°å€å’Œ product_uuid å‡å”¯ä¸€ï¼Œå¼€å§‹é›†ç¾¤åˆå§‹åŒ–ä¹‹å‰éœ€è¦æ£€æŸ¥ç›¸å…³ä¿¡æ¯

```bash
# æ£€æŸ¥macåœ°å€
ip link
ifconfig -a

# æ£€æŸ¥product_uuid
sudo cat /sys/class/dmi/id/product_uuid
```

### 1.5 é…ç½® ssh å…å¯†ç™»å½•

```bash
# åœ¨rootç”¨æˆ·ä¸‹é¢ç”Ÿæˆä¸€ä¸ªå…¬ç”¨çš„keyï¼Œå¹¶é…ç½®å¯ä»¥ä½¿ç”¨è¯¥keyå…å¯†ç™»å½•
su root
ssh-keygen
cd /root/.ssh/
cat id_rsa.pub >> authorized_keys
chmod 600 authorized_keys

cat >> ~/.ssh/config <<EOF
Host free00
    HostName 172.16.0.175
    User root
    Port 22
    IdentityFile ~/.ssh/id_rsa

Host free01
    HostName 172.16.0.167
    User root
    Port 22
    IdentityFile ~/.ssh/id_rsa

Host free02
    HostName 172.16.0.168
    User root
    Port 22
    IdentityFile ~/.ssh/id_rsa

Host free03
    HostName 172.16.0.170
    User root
    Port 22
    IdentityFile ~/.ssh/id_rsa
EOF

ssh-copy-id -p 22 free00
ssh-copy-id -p 22 free01
ssh-copy-id -p 22 free02
ssh-copy-id -p 22 free03
```

### 1.6 å…³é—­ swap å†…å­˜

```bash
# ä½¿ç”¨å‘½ä»¤ç›´æ¥å…³é—­swapå†…å­˜
swapoff -a

# ä¿®æ”¹fstabæ–‡ä»¶ç¦æ­¢å¼€æœºè‡ªåŠ¨æŒ‚è½½swapåˆ†åŒº
sed -i '/swap / s/^\(.*\)$/#\1/g' /etc/fstab
```

### 1.7 å…³é—­ selinux

```bash
# ä½¿ç”¨å‘½ä»¤ç›´æ¥å…³é—­
setenforce 0

# ä¹Ÿå¯ä»¥ç›´æ¥ä¿®æ”¹/etc/selinux/configæ–‡ä»¶
sed -i 's/^SELINUX=enforcing$/SELINUX=disabled/' /etc/selinux/config
```

### 1.8 é…ç½® netfilter å‚æ•°

è¿™é‡Œä¸»è¦æ˜¯éœ€è¦é…ç½®å†…æ ¸åŠ è½½ br_netfilter å’Œ iptables æ”¾è¡Œ ipv6 å’Œ ipv4 çš„æµé‡ï¼Œç¡®ä¿é›†ç¾¤å†…çš„å®¹å™¨èƒ½å¤Ÿæ­£å¸¸é€šä¿¡ã€‚

```bash
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
br_netfilter
EOF

cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
sudo sysctl --system
```

### 1.9 é…ç½® ipvs

å¦‚æœæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ cilium æ¥å®Œå…¨æ›¿ä»£ kube-proxyï¼Œé‚£ä¹ˆå®é™…ä¸Šå°±ç”¨ä¸åˆ° ipvs å’Œ iptablesï¼Œå› æ­¤è¿™ä¸€æ­¥ç†è®ºä¸Šæ˜¯å¯ä»¥è·³è¿‡çš„ã€‚

## 2. CNI ç»„ä»¶é€‰æ‹©

### 2.1 Cilium

[1. Cilium ä¾èµ–](https://wiki.moweilong.com/sre/cilium/Cilium%20%E4%BE%9D%E8%B5%96.html)

[2. å†…æ ¸å‡çº§](https://wiki.moweilong.com/sre/linux/CentOS7%20%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7.html)

[3. å†…æ ¸é…ç½®](https://wiki.moweilong.com/sre/linux/CentOS7%20å†…æ ¸é…ç½®.html)

## 3. å®‰è£… container runtime

è¯¦ç»†çš„å®˜æ–¹æ–‡æ¡£å¯ä»¥å‚è€ƒ[è¿™é‡Œ](https://kubernetes.io/docs/setup/production-environment/container-runtimes/)ï¼Œç”±äºåœ¨å‘å¸ƒçš„ 1.24 ç‰ˆæœ¬ä¸­ç§»é™¤äº† docker-shimï¼Œå› æ­¤å®‰è£…çš„ç‰ˆæœ¬ â‰¥1.24 çš„æ—¶å€™éœ€è¦æ³¨æ„å®¹å™¨è¿è¡Œæ—¶çš„é€‰æ‹©ã€‚è¿™é‡Œæˆ‘ä»¬å®‰è£…çš„ç‰ˆæœ¬ä¸ºæœ€æ–°çš„ 1.24ï¼Œå› æ­¤æˆ‘ä»¬ä¸èƒ½ç»§ç»­ä½¿ç”¨ dockerï¼Œè¿™é‡Œæˆ‘ä»¬å°†å…¶æ¢ä¸º[containerd](https://kubernetes.io/docs/setup/production-environment/container-runtimes/#containerd)

### 3.1 ä¿®æ”¹ Linux å†…æ ¸å‚æ•°

```bash
# é¦–å…ˆç”Ÿæˆé…ç½®æ–‡ä»¶ç¡®ä¿é…ç½®æŒä¹…åŒ–
cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# Setup required sysctl params, these persist across reboots.
cat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF

# Apply sysctl params without reboot
sudo sysctl --system
```

### 3.2 å®‰è£… containerd

```bash
# å¯¼å…¥ docker å®˜æ–¹çš„ yum æº
sudo yum install -y yum-utils device-mapper-persistent-data lvm2

sudo yum-config-manager --add-repo  https://download.docker.com/linux/centos/docker-ce.repo

# æŸ¥çœ‹ yum æºä¸­å­˜åœ¨çš„å„ä¸ªç‰ˆæœ¬çš„ containerd.io
yum list containerd.io --showduplicates | sort -r

# å®‰è£… kubekey æ¨èç‰ˆæœ¬çš„ containerd.io
yum install containerd.io-1.6.4-3.1.el7.x86_64 -y

# ä¹Ÿå¯ä»¥å®‰è£…æœ€æ–°ç‰ˆæœ¬
yum install containerd -y

# è®¾ç½®ä¸€ä¸‹å¼€æœºå¯åŠ¨
sudo systemctl enable --now containerd

sudo systemctl status containerd
```

### 3.3 å…³äº CRI

å®˜æ–¹è¡¨ç¤ºï¼Œå¯¹äº k8s æ¥è¯´ï¼Œä¸éœ€è¦å®‰è£… cri-containerdï¼Œå¹¶ä¸”è¯¥åŠŸèƒ½ä¼šåœ¨åé¢çš„ 2.0 ç‰ˆæœ¬ä¸­åºŸå¼ƒã€‚

::: tip
FAQ: For Kubernetes, do I need to download cri-containerd-(cni-)<\VERSION>-<\OS-<\ARCH>.tar.gz too?
Answer: No.
As the Kubernetes CRI feature has been already included in containerd-<\VERSION>-OS>-ARCH>.tar.gz, you do not need to download the cri-containerd-.... archives to use CRI.
The cri-containerd-... archives are [deprecated](https://github.com/containerd/containerd/blob/main/RELEASES.md#deprecated-features), do not work on old Linux distributions, and will be removed in containerd 2.0.
:::

### 3.4 å®‰è£… cni-plugins

ä½¿ç”¨ yum æºå®‰è£…çš„æ–¹å¼ä¼šæŠŠ runc å®‰è£…å¥½ï¼Œä½†æ˜¯å¹¶ä¸ä¼šå®‰è£… cni-pluginsï¼Œå› æ­¤è¿™éƒ¨åˆ†è¿˜æ˜¯éœ€è¦æˆ‘ä»¬è‡ªè¡Œå®‰è£…ã€‚

::: tip
The containerd.io package contains runc too, but does not contain CNI plugins.
:::

æˆ‘ä»¬ç›´æ¥åœ¨ [github](https://github.com/containernetworking/plugins/releases) ä¸Šé¢æ‰¾åˆ°ç³»ç»Ÿå¯¹åº”çš„æ¶æ„ç‰ˆæœ¬ï¼Œè¿™é‡Œä¸º amd64ï¼Œç„¶åè§£å‹å³å¯ã€‚

```bash
# Download the cni-plugins-<OS>-<ARCH>-<VERSION>.tgz archive from https://github.com/containernetworking/plugins/releases , verify its sha256sum, and extract it under /opt/cni/bin:

export CNI_VERSION=v1.3.0
# ä¸‹è½½æºæ–‡ä»¶å’Œsha512æ–‡ä»¶å¹¶æ ¡éªŒ
wget https://ghproxy.com/https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-amd64-${CNI_VERSION}.tgz

wget https://ghproxy.com/https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-amd64-${CNI_VERSION}.tgz.sha512

sha512sum -c cni-plugins-linux-amd64-${CNI_VERSION}.tgz.sha512

# åˆ›å»ºç›®å½•å¹¶è§£å‹
mkdir -p /opt/cni/bin
tar Cxzvf /opt/cni/bin cni-plugins-linux-amd64-${CNI_VERSION}.tgz
```

### 3.5 é…ç½® cgroup drivers

CentOS7 ä½¿ç”¨çš„æ˜¯ systemd æ¥åˆå§‹åŒ–ç³»ç»Ÿå¹¶ç®¡ç†è¿›ç¨‹ï¼Œåˆå§‹åŒ–è¿›ç¨‹ä¼šç”Ÿæˆå¹¶ä½¿ç”¨ä¸€ä¸ª root æ§åˆ¶ç»„ (cgroup), å¹¶å……å½“ cgroup ç®¡ç†å™¨ã€‚ Systemd ä¸ cgroup é›†æˆç´§å¯†ï¼Œå¹¶å°†ä¸ºæ¯ä¸ª systemd å•å…ƒåˆ†é…ä¸€ä¸ª cgroupã€‚ æˆ‘ä»¬ä¹Ÿå¯ä»¥é…ç½®å®¹å™¨è¿è¡Œæ—¶å’Œ kubelet ä½¿ç”¨ cgroupfsã€‚ è¿åŒ systemd ä¸€èµ·ä½¿ç”¨ cgroupfs æ„å‘³ç€å°†æœ‰ä¸¤ä¸ªä¸åŒçš„ cgroup ç®¡ç†å™¨ã€‚è€Œå½“ä¸€ä¸ªç³»ç»Ÿä¸­åŒæ—¶å­˜åœ¨ cgroupfs å’Œ systemd ä¸¤è€…æ—¶ï¼Œå®¹æ˜“å˜å¾—ä¸ç¨³å®šï¼Œå› æ­¤æœ€å¥½æ›´æ”¹è®¾ç½®ï¼Œä»¤å®¹å™¨è¿è¡Œæ—¶å’Œ kubelet ä½¿ç”¨ systemd ä½œä¸º cgroup é©±åŠ¨ï¼Œä»¥æ­¤ä½¿ç³»ç»Ÿæ›´ä¸ºç¨³å®šã€‚ å¯¹äº containerd, éœ€è¦è®¾ç½®é…ç½®æ–‡ä»¶/etc/containerd/config.toml ä¸­çš„ SystemdCgroup å‚æ•°ã€‚

å‚è€ƒ k8s å®˜æ–¹çš„[è¯´æ˜æ–‡æ¡£](https://kubernetes.io/docs/setup/production-environment/container-runtimes/#containerd-systemd)ï¼š

kubekey containerd ä½¿ç”¨çš„é…ç½®

```bash
vi /etc/containerd/config.toml
```

```toml
version = 2
root = "/var/lib/containerd"
state = "/run/containerd"

[grpc]
address = "/run/containerd/containerd.sock"
uid = 0
gid = 0
max_recv_message_size = 16777216
max_send_message_size = 16777216

[ttrpc]
address = ""
uid = 0
gid = 0

[debug]
address = ""
uid = 0
gid = 0
level = ""

[metrics]
address = ""
grpc_histogram = false

[cgroup]
path = ""

[timeouts]
"io.containerd.timeout.shim.cleanup" = "5s"
"io.containerd.timeout.shim.load" = "5s"
"io.containerd.timeout.shim.shutdown" = "3s"
"io.containerd.timeout.task.state" = "2s"

[plugins]
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
runtime_type = "io.containerd.runc.v2"
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
SystemdCgroup = true
[plugins."io.containerd.grpc.v1.cri"]
sandbox_image = "registry.aliyuncs.com/google_containers/pause:3.9"
[plugins."io.containerd.grpc.v1.cri".cni]
bin_dir = "/opt/cni/bin"
conf_dir = "/etc/cni/net.d"
max_conf_num = 1
conf_template = ""
[plugins."io.containerd.grpc.v1.cri".registry]
[plugins."io.containerd.grpc.v1.cri".registry.mirrors]
[plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]
endpoint = ["https://registry-1.docker.io"]
```

é‡å¯æœåŠ¡

```bash
systemctl restart containerd

systemctl status containerd
```

### 3.6 å…³äº kubelet çš„ cgroup driver

k8s å®˜æ–¹æœ‰[è¯¦ç»†çš„æ–‡æ¡£](https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/)ä»‹ç»äº†å¦‚ä½•è®¾ç½® kubelet çš„ cgroup driverï¼Œéœ€è¦ç‰¹åˆ«æ³¨æ„çš„æ˜¯ï¼Œåœ¨ 1.22 ç‰ˆæœ¬å¼€å§‹ï¼Œå¦‚æœæ²¡æœ‰æ‰‹åŠ¨è®¾ç½® kubelet çš„ cgroup driverï¼Œé‚£ä¹ˆé»˜è®¤ä¼šè®¾ç½®ä¸º systemd

::: tip
Note:
In v1.22 and later, if the user does not set the cgroupDriver field under KubeletConfiguration, kubeadm defaults it to systemd.

In Kubernetes v1.28, you can enable automatic detection of the cgroup driver as an alpha feature. See systemd cgroup driver for more details.
:::

ä¸€ä¸ªæ¯”è¾ƒç®€å•çš„æŒ‡å®š kubelet çš„ cgroup driver çš„æ–¹æ³•å°±æ˜¯åœ¨ kubeadm-config.yaml åŠ å…¥ cgroupDriver å­—æ®µ

```yaml
# kubeadm-config.yaml
kind: ClusterConfiguration
apiVersion: kubeadm.k8s.io/v1beta3
kubernetesVersion: v1.21.0
---
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
cgroupDriver: systemd
```

æˆ‘ä»¬å¯ä»¥ç›´æ¥æŸ¥çœ‹ configmaps æ¥æŸ¥çœ‹åˆå§‹åŒ–ä¹‹åé›†ç¾¤çš„ kubeadm-config é…ç½®ã€‚

```bash
kubectl describe configmaps kubeadm-config -n kube-system
```

å½“ç„¶å› ä¸ºæˆ‘ä»¬éœ€è¦å®‰è£…çš„ç‰ˆæœ¬é«˜äº 1.22.0 å¹¶ä¸”ä½¿ç”¨çš„å°±æ˜¯ systemdï¼Œå› æ­¤å¯ä»¥ä¸ç”¨å†é‡å¤é…ç½®ã€‚

### 3.7 å®‰è£… cri-tools

[cri-tools](https://github.com/kubernetes-sigs/cri-tools/releases)è®¾ç½®ç‰ˆæœ¬å’Œ k8s ç¬¬äºŒä¸ªç‰ˆæœ¬å¯¹åº”å³å¯

```bash
VERSION="v1.28.0"

wget https://ghproxy.com/https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-amd64.tar.gz

tar zxvf crictl-$VERSION-linux-amd64.tar.gz -C /usr/local/bin
```

é…ç½® crictl

```bash
vi /etc/crictl.yaml
```

```yaml
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
timeout: 5
debug: false
pull-image-on-create: false
```

éªŒè¯

```bash
crictl version
```

## 4. å®‰è£… kube ç»„ä»¶

å¯¹åº”çš„å®˜æ–¹æ–‡æ¡£å¯ä»¥å‚è€ƒ[è¿™é‡Œ](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl)

kube ä¸‰ä»¶å¥—å°±æ˜¯ kubeadmã€kubelet å’Œ kubectlï¼Œä¸‰è€…çš„å…·ä½“åŠŸèƒ½å’Œä½œç”¨å¦‚ä¸‹ï¼š

- kubeadmï¼šç”¨æ¥åˆå§‹åŒ–é›†ç¾¤çš„æŒ‡ä»¤ã€‚
- kubeletï¼šåœ¨é›†ç¾¤ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ä¸Šç”¨æ¥å¯åŠ¨ Pod å’Œå®¹å™¨ç­‰ã€‚
- kubectlï¼šç”¨æ¥ä¸é›†ç¾¤é€šä¿¡çš„å‘½ä»¤è¡Œå·¥å…·ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼š

- kubeadm ä¸ä¼šå¸®åŠ©æˆ‘ä»¬ç®¡ç† kubelet å’Œ kubectlï¼Œå…¶ä»–ä¸¤è€…ä¹Ÿæ˜¯ä¸€æ ·çš„ï¼Œä¹Ÿå°±æ˜¯è¯´è¿™ä¸‰è€…æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œå¹¶ä¸å­˜åœ¨è°ç®¡ç†è°çš„æƒ…å†µï¼›
- kubelet çš„ç‰ˆæœ¬å¿…é¡»å°äºç­‰äº API-server çš„ç‰ˆæœ¬ï¼Œå¦åˆ™å®¹æ˜“å‡ºç°å…¼å®¹æ€§çš„é—®é¢˜ï¼›
- kubectl å¹¶ä¸æ˜¯é›†ç¾¤ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹éƒ½éœ€è¦å®‰è£…ï¼Œä¹Ÿå¹¶ä¸æ˜¯ä¸€å®šè¦å®‰è£…åœ¨é›†ç¾¤ä¸­çš„èŠ‚ç‚¹ï¼Œå¯ä»¥å•ç‹¬å®‰è£…åœ¨è‡ªå·±æœ¬åœ°çš„æœºå™¨ç¯å¢ƒä¸Šé¢ï¼Œç„¶åé…åˆ kubeconfig æ–‡ä»¶å³å¯ä½¿ç”¨ kubectl å‘½ä»¤æ¥è¿œç¨‹ç®¡ç†å¯¹åº”çš„ k8s é›†ç¾¤ï¼›

CentOS7 çš„å®‰è£…æ¯”è¾ƒç®€å•ï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨å®˜æ–¹æä¾›çš„ yum æºå³å¯ã€‚éœ€è¦æ³¨æ„çš„æ˜¯è¿™é‡Œéœ€è¦è®¾ç½® selinux çš„çŠ¶æ€ï¼Œä½†æ˜¯å‰é¢æˆ‘ä»¬å·²ç»å…³é—­äº† selinuxï¼Œå› æ­¤è¿™é‡Œç•¥è¿‡è¿™æ­¥ã€‚

yum æº

```bash
# ç›´æ¥å¯¼å…¥è°·æ­Œå®˜æ–¹çš„yumæº
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF

# å½“ç„¶å¦‚æœè¿ä¸ä¸Šè°·æ­Œçš„æºï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨å›½å†…çš„é˜¿é‡Œé•œåƒæº el7 el8 é€šç”¨
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
```

å®‰è£…ä¸‰ä»¶å¥—

```bash
# æˆ‘ä»¬è¦å®‰è£…çš„k8sç‰ˆæœ¬æ˜¯æœ€æ–°ç‰ˆæœ¬çš„ï¼Œä½¿ç”¨è¿™ä¸ªå‘½ä»¤
sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

# å¦‚æœç½‘ç»œç¯å¢ƒä¸å¥½å‡ºç°gpgcheckéªŒè¯å¤±è´¥å¯¼è‡´æ— æ³•æ­£å¸¸è¯»å–yumæºï¼Œå¯ä»¥è€ƒè™‘å…³é—­è¯¥yumæºçš„repo_gpgcheck
sed -i 's/repo_gpgcheck=1/repo_gpgcheck=0/g' /etc/yum.repos.d/kubernetes.repo

# æˆ–è€…åœ¨å®‰è£…çš„æ—¶å€™ç¦ç”¨gpgcheck
sudo yum install -y kubelet kubeadm kubectl --nogpgcheck --disableexcludes=kubernetes

# å¦‚æœæƒ³è¦å®‰è£…ç‰¹å®šç‰ˆæœ¬ï¼Œå¯ä»¥ä½¿ç”¨è¿™ä¸ªå‘½ä»¤æŸ¥çœ‹ç›¸å…³ç‰ˆæœ¬çš„ä¿¡æ¯
sudo yum list --nogpgcheck kubelet kubeadm kubectl --showduplicates --disableexcludes=kubernetes

sudo yum install -y kubelet-1.26.7-0 kubeadm-1.26.7-0 kubectl-1.26.7-0 --disableexcludes=kubernetes
```

é…ç½®å¼€æœºè‡ªå¯ kubelet

```bash
sudo systemctl enable --now kubelet
```

## 5. é«˜å¯ç”¨é…ç½®

keepalive å’Œ haproxy

## 6. åˆå§‹åŒ–é›†ç¾¤

### 6.1 åˆå§‹åŒ–é›†ç¾¤é…ç½®

æˆ‘ä»¬å…ˆä½¿ç”¨ kubeadm å‘½ä»¤æŸ¥çœ‹ä¸€ä¸‹ä¸»è¦çš„å‡ ä¸ªé•œåƒç‰ˆæœ¬

```bash
kubeadm config images list
```

è¾“å‡º

```bash
registry.k8s.io/kube-apiserver:v1.28.2
registry.k8s.io/kube-controller-manager:v1.28.2
registry.k8s.io/kube-scheduler:v1.28.2
registry.k8s.io/kube-proxy:v1.28.2
registry.k8s.io/pause:3.9
registry.k8s.io/etcd:3.5.9-0
registry.k8s.io/coredns/coredns:v1.10.1
```

ä¸ºäº†æ–¹ä¾¿ç¼–è¾‘å’Œç®¡ç†ï¼Œæˆ‘ä»¬è¿˜æ˜¯æŠŠåˆå§‹åŒ–å‚æ•°å¯¼å‡ºæˆé…ç½®æ–‡ä»¶

```bash
kubeadm config print init-defaults > kubeadm-kubeproxy-free.conf
```

ä¿®æ”¹é…ç½®æ–‡ä»¶:

- è€ƒè™‘åˆ°å¤§å¤šæ•°æƒ…å†µä¸‹å›½å†…çš„ç½‘ç»œæ— æ³•ä½¿ç”¨è°·æ­Œçš„ k8s.gcr.io é•œåƒæºï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥åœ¨é…ç½®æ–‡ä»¶ä¸­ä¿®æ”¹ imageRepository å‚æ•°ä¸ºé˜¿é‡Œçš„é•œåƒæº
- kubernetesVersion å­—æ®µç”¨æ¥æŒ‡å®šæˆ‘ä»¬è¦å®‰è£…çš„ k8s ç‰ˆæœ¬
- criSocket ä» 1.24.0 ç‰ˆæœ¬å¼€å§‹å·²ç»é»˜è®¤å˜æˆäº† containerd
- ä¿®æ”¹ etcd å­˜å‚¨è·¯å¾„
- controlPlaneEndpoint é…ç½®ä¸º slb çš„åœ°å€ç«¯å£
- podSubnetã€serviceSubnet å’Œ dnsDomain ä¸¤ä¸ªå‚æ•°é»˜è®¤æƒ…å†µä¸‹å¯ä»¥ä¸ç”¨ä¿®æ”¹ï¼Œè¿™é‡Œæˆ‘æŒ‰ç…§è‡ªå·±çš„éœ€æ±‚è¿›è¡Œäº†å˜æ›´

```bash
apiServer:
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta3
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.aliyuncs.com/google_containers
kind: ClusterConfiguration
controlPlaneEndpoint: 172.16.0.200:16443
kubernetesVersion: 1.28.2
networking:
  dnsDomain: cluster.local
  serviceSubnet: 10.18.0.0/18
  podSubnet: 10.18.64.0/18
```

### 6.2 åˆå§‹åŒ–é›†ç¾¤

æ­¤æ—¶æˆ‘ä»¬å†æŸ¥çœ‹å¯¹åº”çš„é…ç½®æ–‡ä»¶ä¸­çš„é•œåƒç‰ˆæœ¬ï¼Œå°±ä¼šå‘ç°å·²ç»å˜æˆäº†å¯¹åº”é˜¿é‡Œäº‘é•œåƒæºçš„ç‰ˆæœ¬

æˆ‘ä»¬å¯ä»¥åœ¨[é›†ç¾¤åˆå§‹åŒ–](https://kubernetes.io/zh-cn/docs/reference/setup-tools/kubeadm/kubeadm-init/)çš„æ—¶å€™æ·»åŠ å‚æ•° `--skip-phases=addon/kube-proxy` è·³è¿‡ kube-proxy çš„å®‰è£…

æŸ¥çœ‹ä¸€ä¸‹å¯¹åº”çš„é•œåƒç‰ˆæœ¬ï¼Œç¡®å®šé…ç½®æ–‡ä»¶æ˜¯å¦ç”Ÿæ•ˆ

```bash
kubeadm config images list --config  kubeadm-kubeproxy-free.conf
```

è¾“å‡º

```bash
registry.aliyuncs.com/google_containers/kube-apiserver:v1.28.2
registry.aliyuncs.com/google_containers/kube-controller-manager:v1.28.2
registry.aliyuncs.com/google_containers/kube-scheduler:v1.28.2
registry.aliyuncs.com/google_containers/kube-proxy:v1.28.2
registry.aliyuncs.com/google_containers/pause:3.9
registry.aliyuncs.com/google_containers/etcd:3.5.9-0
registry.aliyuncs.com/google_containers/coredns:v1.10.1
```

ç¡®è®¤æ²¡é—®é¢˜ä¹‹åæˆ‘ä»¬ç›´æ¥æ‹‰å–é•œåƒ

```bash
kubeadm config images pull --config kubeadm-kubeproxy-free.conf
```

åˆå§‹åŒ–ï¼Œæ³¨æ„æ·»åŠ å‚æ•°è·³è¿‡ kube-proxy çš„å®‰è£…

```bash
kubeadm init --config kubeadm-kubeproxy-free.conf --skip-phases=addon/kube-proxy
```

å½“æˆ‘ä»¬çœ‹åˆ°ä¸‹é¢è¿™ä¸ªè¾“å‡ºç»“æœçš„æ—¶å€™ï¼Œæˆ‘ä»¬çš„é›†ç¾¤å°±ç®—æ˜¯åˆå§‹åŒ–æˆåŠŸäº†

```bash
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of control-plane nodes by copying certificate authorities
and service account keys on each node and then running the following as root:

  kubeadm join 172.16.0.200:16443 --token 7cwlcl.from7wfu1rgyfluf \
        --discovery-token-ca-cert-hash sha256:6ee757429ad9eb56048de2963f3bc66f228abb0895edde2cbe2c1f85ff9d58b8 \
        --control-plane

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 172.16.0.200:16443 --token 7cwlcl.from7wfu1rgyfluf \
        --discovery-token-ca-cert-hash sha256:6ee757429ad9eb56048de2963f3bc66f228abb0895edde2cbe2c1f85ff9d58b8
```

åˆšåˆå§‹åŒ–æˆåŠŸä¹‹åï¼Œæˆ‘ä»¬è¿˜æ²¡åŠæ³•é©¬ä¸ŠæŸ¥çœ‹ k8s é›†ç¾¤ä¿¡æ¯ï¼Œéœ€è¦é…ç½® kubeconfig ç›¸å…³å‚æ•°æ‰èƒ½æ­£å¸¸ä½¿ç”¨ kubectl è¿æ¥ apiserver è¯»å–é›†ç¾¤ä¿¡æ¯ã€‚

```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

æ·»åŠ  kubectl çš„è‡ªåŠ¨è¡¥å…¨åŠŸèƒ½

```bash
echo "source <(kubectl completion bash)" >> ~/.bashrc

# å®‰è£…å®Œæˆåé‡æ–°ç™»é™†shell
yum install bash-completion -y
```

é…ç½®å®Œæˆåï¼Œæˆ‘ä»¬å†æ‰§è¡Œç›¸å…³å‘½ä»¤å°±å¯ä»¥æŸ¥çœ‹é›†ç¾¤çš„ä¿¡æ¯äº†ã€‚

```bash
kubectl cluster-info

kubectl get nodes -o wide

kubectl get pod -A
```

è¿™æ—¶å€™æŸ¥çœ‹ daemonset å¯ä»¥çœ‹åˆ°æ˜¯æ²¡æœ‰ kube-proxy çš„

```bash
kubectl get ds -A
```

master02 master03 æ‰§è¡Œ

```bash
mkdir -p /etc/kubernetes/pki/etcd
```

æ‹·è´è¯ä¹¦åˆ° master02 master03 èŠ‚ç‚¹

```bash
scp /etc/kubernetes/pki/ca.* /etc/kubernetes/pki/sa.* /etc/kubernetes/pki/front-proxy-ca.* free01:/etc/kubernetes/pki/

scp /etc/kubernetes/pki/etcd/ca.* free01:/etc/kubernetes/pki/etcd/

scp /etc/kubernetes/pki/ca.* /etc/kubernetes/pki/sa.* /etc/kubernetes/pki/front-proxy-ca.* free03:/etc/kubernetes/pki/

scp /etc/kubernetes/pki/etcd/ca.* free03:/etc/kubernetes/pki/etcd/
```

master02 master03 æ‰§è¡Œå‘½ä»¤åŠ å…¥ master

```
  kubeadm join 172.16.0.200:16443 --token 7cwlcl.from7wfu1rgyfluf \
        --discovery-token-ca-cert-hash sha256:6ee757429ad9eb56048de2963f3bc66f228abb0895edde2cbe2c1f85ff9d58b8 \
        --control-plane
```

### 6.3 æ·»åŠ  worker èŠ‚ç‚¹

è¿™æ—¶å€™æˆ‘ä»¬è¿˜éœ€è¦ç»§ç»­æ·»åŠ å‰©ä¸‹çš„èŠ‚ç‚¹ä½œä¸º worker èŠ‚ç‚¹è¿è¡Œè´Ÿè½½ï¼Œç›´æ¥åœ¨å‰©ä¸‹çš„èŠ‚ç‚¹ä¸Šé¢è¿è¡Œé›†ç¾¤åˆå§‹åŒ–æˆåŠŸæ—¶è¾“å‡ºçš„å‘½ä»¤å°±å¯ä»¥æˆåŠŸåŠ å…¥é›†ç¾¤ã€‚

å› ä¸ºæˆ‘ä»¬å‰é¢çš„ kubeadm åˆå§‹åŒ– master èŠ‚ç‚¹çš„æ—¶å€™æ²¡æœ‰å¯ç”¨ kube-proxyï¼Œæ‰€ä»¥åœ¨æ·»åŠ èŠ‚ç‚¹çš„æ—¶å€™ä¼šå‡ºç°è­¦å‘Šï¼Œä½†æ˜¯ä¸å½±å“æˆ‘ä»¬ç»§ç»­æ·»åŠ èŠ‚ç‚¹

```bash
kubeadm join 172.16.0.200:16443 --token 7cwlcl.from7wfu1rgyfluf \
        --discovery-token-ca-cert-hash sha256:6ee757429ad9eb56048de2963f3bc66f228abb0895edde2cbe2c1f85ff9d58b8
```

å¦‚æœä¸å°å¿ƒæ²¡ä¿å­˜åˆå§‹åŒ–æˆåŠŸçš„è¾“å‡ºä¿¡æ¯ä¹Ÿæ²¡æœ‰å…³ç³»ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ kubectl å·¥å…·æŸ¥çœ‹æˆ–è€…ç”Ÿæˆ token

```bash
# æŸ¥çœ‹ç°æœ‰çš„tokenåˆ—è¡¨
kubeadm token list

# å¦‚æœtokenå·²ç»å¤±æ•ˆï¼Œé‚£å°±å†åˆ›å»ºä¸€ä¸ªæ–°çš„token
kubeadm token create

# å¦‚æœæ‰¾ä¸åˆ°--discovery-token-ca-cert-hashå‚æ•°ï¼Œåˆ™å¯ä»¥åœ¨masterèŠ‚ç‚¹ä¸Šä½¿ç”¨opensslå·¥å…·æ¥è·å–
openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'

# è¾“å‡º 90f0a5e68b57d00d3f92a59f1464dfe0e7d8115365dc902fcdf596f8c1744445

kubeadm join 172.16.0.200:16443 --token 9xs6nr.zdwayftngv9l9jl7 \
        --discovery-token-ca-cert-hash sha256:90f0a5e68b57d00d3f92a59f1464dfe0e7d8115365dc902fcdf596f8c1744445
```

æ·»åŠ å®Œæˆä¹‹åæˆ‘ä»¬å†æŸ¥çœ‹é›†ç¾¤çš„èŠ‚ç‚¹å¯ä»¥å‘ç°çŠ¶æ€è¿˜æ˜¯ NotReadyï¼Œæ¥ä¸‹æ¥å°±éœ€è¦éƒ¨ç½² CNI äº†ã€‚

## 7. å®‰è£… CNI

### 7.1 å®‰è£… helm3

cilium çš„éƒ¨ç½²ä¾èµ– helm3ï¼Œå› æ­¤æˆ‘ä»¬åœ¨éƒ¨ç½² cilium ä¹‹å‰éœ€è¦å…ˆå®‰è£… [helm3](https://helm.sh/zh/docs/intro/install/#%E7%94%A8%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85)ã€‚

é€šè¿‡[äºŒè¿›åˆ¶åŒ…](https://github.com/helm/helm/releases)å®‰è£…

```bash
# å›½å†…å¤ªæ…¢äº†
wget https://get.helm.sh/helm-v3.13.1-linux-amd64.tar.gz

tar -zxvf helm-v3.13.1-linux-amd64.tar.gz

cp -rp linux-amd64/helm /usr/local/bin/

helm version
```

### 7.2 å®‰è£… Cilium

å®Œæ•´çš„éƒ¨ç½²æŒ‡å—å¯ä»¥å‚è€ƒå®˜æ–¹æ–‡æ¡£ï¼Œé¦–å…ˆæˆ‘ä»¬æ·»åŠ  helm çš„ repoã€‚

```bash
helm repo add cilium https://helm.cilium.io/

helm repo list
```

å‚è€ƒå®˜ç½‘çš„[æ–‡æ¡£](https://docs.cilium.io/en/stable/installation/k8s-install-helm/)ï¼Œè¿™é‡Œæˆ‘ä»¬éœ€è¦æŒ‡å®šé›†ç¾¤çš„ APIserver çš„ IP å’Œç«¯å£

```bash
helm install cilium ./cilium \
    --namespace kube-system \
    --set kubeProxyReplacement=true \
    --set k8sServiceHost=REPLACE_WITH_API_SERVER_IP \
    --set k8sServicePort=REPLACE_WITH_API_SERVER_PORT
```

ä½†æ˜¯è€ƒè™‘åˆ° cilium é»˜è®¤ä½¿ç”¨çš„ podCIDR ä¸º 10.0.0.0/8ï¼Œå¾ˆå¯èƒ½ä¼šå’Œæˆ‘ä»¬é›†ç¾¤å†…çš„ç½‘ç»œå†²çªï¼Œæœ€å¥½çš„æ–¹æ¡ˆå°±æ˜¯åˆå§‹åŒ–çš„æ—¶å€™æŒ‡å®š podCIDRï¼Œå…³äºåˆå§‹åŒ–çš„æ—¶å€™ podCIDR çš„è®¾ç½®ï¼Œå¯ä»¥å‚è€ƒå®˜æ–¹çš„è¿™ä¸ª[æ–‡ç« ](https://docs.cilium.io/en/stable/network/kubernetes/ipam-cluster-pool/#gsg-ipam-crd-cluster-pool)ã€‚

```bash
helm install cilium cilium/cilium --version 1.14.3 \
    --namespace kube-system \
    --set kubeProxyReplacement=true  \
    --set ipam.mode=cluster-pool      \
    --set k8sServiceHost=REPLACE_WITH_API_SERVER_IP \
    --set k8sServicePort=REPLACE_WITH_API_SERVER_PORT \
	--set ipam.operator.clusterPoolIPv4PodCIDRList=<IPv4CIDR> \
	--set ipam.operator.clusterPoolIPv4MaskSize=<IPv4MaskSize>
```

æœ€åå¯ä»¥å¾—åˆ°æˆ‘ä»¬çš„åˆå§‹åŒ–å®‰è£…å‚æ•°

```bash
helm install cilium cilium/cilium --version 1.14.3 \
    --namespace kube-system \
    --set kubeProxyReplacement=true  \
    --set k8sServiceHost=172.16.0.200 \
    --set k8sServicePort=16443 \
	--set ipam.operator.clusterPoolIPv4PodCIDRList=10.18.64.0/18 \
	--set ipam.operator.clusterPoolIPv4MaskSize=24
```

æ­¤æ—¶æˆ‘ä»¬å†æŸ¥çœ‹é›†ç¾¤çš„ daemonset å’Œ deployment çŠ¶æ€ï¼š

```bash
# è¿™æ—¶å€™æŸ¥çœ‹é›†ç¾¤çš„daemonsetå’ŒdeploymentçŠ¶æ€å¯ä»¥çœ‹åˆ°ciliumç›¸å…³çš„æœåŠ¡å·²ç»æ­£å¸¸
kubectl get ds -A
```

è¾“å‡º

```bash
NAMESPACE     NAME     DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
kube-system   cilium   4         4         4       4            4           kubernetes.io/os=linux   4m21s
```

å†æŸ¥çœ‹æ‰€æœ‰çš„ podï¼ŒçŠ¶æ€éƒ½æ­£å¸¸ï¼Œip ä¹Ÿå’Œæˆ‘ä»¬åˆå§‹åŒ–çš„æ—¶å€™åˆ†é…çš„ ip æ®µä¸€è‡´ï¼Œè¯´æ˜åˆå§‹åŒ–çš„å‚æ•°è®¾ç½®ç”Ÿæ•ˆäº†ã€‚

```bash
# å†æŸ¥çœ‹æ‰€æœ‰çš„podï¼ŒçŠ¶æ€éƒ½æ­£å¸¸ï¼ŒipæŒ‰é¢„æœŸè¿›è¡Œäº†åˆ†é…
kubectl get pods -A -o wide
```

è¾“å‡º

```bash
NAMESPACE     NAME                               READY   STATUS              RESTARTS   AGE     IP             NODE     NOMINATED NODE   READINESS GATES
kube-system   cilium-gr2j4                       1/1     Running             0          5m31s   172.16.0.167   free01   <none>           <none>
kube-system   cilium-j9ld5                       1/1     Running             0          5m31s   172.16.0.175   free00   <none>           <none>
kube-system   cilium-mzdqn                       0/1     Running            0          5m31s   172.16.0.170   free02   <none>           <none>
kube-system   cilium-operator-6db6645669-nm6l2   1/1     Running             0          5m30s   172.16.0.175   free00   <none>           <none>
kube-system   cilium-operator-6db6645669-wflt2   0/1     Running             0          5m30s   172.16.0.170   free02   <none>           <none>
kube-system   cilium-rz7fl                       1/1     Running             0          5m31s   172.16.0.168   free03   <none>           <none>
kube-system   coredns-66f779496c-cqzgq           1/1     Running             0          54m     10.18.64.11    free00   <none>           <none>
kube-system   coredns-66f779496c-h6rnw           1/1     Running             0          54m     10.18.64.89    free00   <none>           <none>
kube-system   etcd-free00                        1/1     Running             2          54m     172.16.0.175   free00   <none>           <none>
kube-system   etcd-free01                        1/1     Running             1          49m     172.16.0.167   free01   <none>           <none>
kube-system   etcd-free03                        1/1     Running             1          49m     172.16.0.168   free03   <none>           <none>
kube-system   kube-apiserver-free00              1/1     Running             2          54m     172.16.0.175   free00   <none>           <none>
kube-system   kube-apiserver-free01              1/1     Running             2          49m     172.16.0.167   free01   <none>           <none>
kube-system   kube-apiserver-free03              1/1     Running             1          49m     172.16.0.168   free03   <none>           <none>
kube-system   kube-controller-manager-free00     1/1     Running             3          54m     172.16.0.175   free00   <none>           <none>
kube-system   kube-controller-manager-free01     1/1     Running             2          49m     172.16.0.167   free01   <none>           <none>
kube-system   kube-controller-manager-free03     1/1     Running             1          49m     172.16.0.168   free03   <none>           <none>
kube-system   kube-scheduler-free00              1/1     Running             4          54m     172.16.0.175   free00   <none>           <none>
kube-system   kube-scheduler-free01              1/1     Running             2          49m     172.16.0.167   free01   <none>           <none>
kube-system   kube-scheduler-free03              1/1     Running             1          49m     172.16.0.168   free03   <none>           <none>
```

è¿™æ—¶å€™æˆ‘ä»¬å†è¿›å…¥ pod ä¸­æ£€æŸ¥ cilium çš„çŠ¶æ€

```bash
# --verbose å‚æ•°å¯ä»¥æŸ¥çœ‹è¯¦ç»†çš„çŠ¶æ€ä¿¡æ¯
# cilium-j9ld5     éœ€è¦æ›¿æ¢ä¸ºä»»æ„ä¸€ä¸ªciliumçš„pod
kubectl exec -it -n kube-system cilium-j9ld5  -- cilium status --verbose
```

è¾“å‡º

```bash
Defaulted container "cilium-agent" out of: cilium-agent, config (init), mount-cgroup (init), apply-sysctl-overwrites (init), mount-bpf-fs (init), clean-cilium-state (init), install-cni-binaries (init)
KVStore:                Ok   Disabled
Kubernetes:             Ok   1.28 (v1.28.2) [linux/amd64]
Kubernetes APIs:        ["EndpointSliceOrEndpoint", "cilium/v2::CiliumClusterwideNetworkPolicy", "cilium/v2::CiliumEndpoint", "cilium/v2::CiliumNetworkPolicy", "cilium/v2::CiliumNode", "cilium/v2alpha1::CiliumCIDRGroup", "core/v1::Namespace", "core/v1::Pods", "core/v1::Service", "networking.k8s.io/v1::NetworkPolicy"]
KubeProxyReplacement:   True   [eth0 172.16.0.175 (Direct Routing)]
Host firewall:          Disabled
CNI Chaining:           none
Cilium:                 Ok   1.14.3 (v1.14.3-252a99ef)
NodeMonitor:            Listening for events on 4 CPUs with 64x4096 of shared memory
Cilium health daemon:   Ok
IPAM:                   IPv4: 4/254 allocated from 10.18.64.0/24,
Allocated addresses:
  10.18.64.11 (kube-system/coredns-66f779496c-cqzgq)
  10.18.64.178 (router)
  10.18.64.4 (health)
  10.18.64.89 (kube-system/coredns-66f779496c-h6rnw)
IPv4 BIG TCP:           Disabled
IPv6 BIG TCP:           Disabled
BandwidthManager:       Disabled
Host Routing:           Legacy
Masquerading:           IPTables [IPv4: Enabled, IPv6: Disabled]
Clock Source for BPF:   ktime
Controller Status:      28/28 healthy
  Name                                  Last success   Last error   Count   Message
  cilium-health-ep                      54s ago        never        0       no error
  dns-garbage-collector-job             14s ago        never        0       no error
  endpoint-1030-regeneration-recovery   never          never        0       no error
  endpoint-1262-regeneration-recovery   never          never        0       no error
  endpoint-1389-regeneration-recovery   never          never        0       no error
  endpoint-331-regeneration-recovery    never          never        0       no error
  endpoint-gc                           3m14s ago      never        0       no error
  ipcache-inject-labels                 55s ago        22m58s ago   0       no error
  k8s-heartbeat                         14s ago        never        0       no error
  link-cache                            10s ago        never        0       no error
  metricsmap-bpf-prom-sync              4s ago         never        0       no error
  resolve-identity-1030                 2m55s ago      never        0       no error
  resolve-identity-1262                 2m54s ago      never        0       no error
  resolve-identity-1389                 2m55s ago      never        0       no error
  resolve-identity-331                  2m55s ago      never        0       no error
  sync-host-ips                         55s ago        never        0       no error
  sync-lb-maps-with-k8s-services        22m55s ago     never        0       no error
  sync-policymap-1030                   7m53s ago      never        0       no error
  sync-policymap-1262                   7m54s ago      never        0       no error
  sync-policymap-1389                   7m54s ago      never        0       no error
  sync-policymap-331                    7m54s ago      never        0       no error
  sync-to-k8s-ciliumendpoint (1030)     5s ago         never        0       no error
  sync-to-k8s-ciliumendpoint (1262)     4s ago         never        0       no error
  sync-to-k8s-ciliumendpoint (1389)     5s ago         never        0       no error
  sync-to-k8s-ciliumendpoint (331)      5s ago         never        0       no error
  sync-utime                            55s ago        never        0       no error
  template-dir-watcher                  never          never        0       no error
  write-cni-file                        23m14s ago     never        0       no error
Proxy Status:            OK, ip 10.18.64.178, 0 redirects active on ports 10000-20000, Envoy: embedded
Global Identity Range:   min 256, max 65535
Hubble:                  Ok   Current/Max Flows: 4095/4095 (100.00%), Flows/s: 10.45   Metrics: Disabled
KubeProxyReplacement Details:
  Status:                 True
  Socket LB:              Enabled
  Socket LB Tracing:      Enabled
  Socket LB Coverage:     Full
  Devices:                eth0 172.16.0.175 (Direct Routing)
  Mode:                   SNAT
  Backend Selection:      Random
  Session Affinity:       Enabled
  Graceful Termination:   Enabled
  NAT46/64 Support:       Disabled
  XDP Acceleration:       Disabled
  Services:
  - ClusterIP:      Enabled
  - NodePort:       Enabled (Range: 30000-32767)
  - LoadBalancer:   Enabled
  - externalIPs:    Enabled
  - HostPort:       Enabled
BPF Maps:   dynamic sizing: on (ratio: 0.002500)
  Name                          Size
  Auth                          524288
  Non-TCP connection tracking   72322
  TCP connection tracking       144645
  Endpoint policy               65535
  IP cache                      512000
  IPv4 masquerading agent       16384
  IPv6 masquerading agent       16384
  IPv4 fragmentation            8192
  IPv4 service                  65536
  IPv6 service                  65536
  IPv4 service backend          65536
  IPv6 service backend          65536
  IPv4 service reverse NAT      65536
  IPv6 service reverse NAT      65536
  Metrics                       1024
  NAT                           144645
  Neighbor table                144645
  Global policy                 16384
  Session affinity              65536
  Sock reverse NAT              72322
  Tunnel                        65536
Encryption:            Disabled
Cluster health:        4/4 reachable   (2023-10-20T08:14:57Z)
  Name                 IP              Node        Endpoints
  free00 (localhost)   172.16.0.175    reachable   reachable
  free01               172.16.0.167    reachable   reachable
  free02               172.16.0.170    reachable   reachable
  free03               172.16.0.168    reachable   reachable
```

å…¶å®åˆ°è¿™é‡Œ cilium çš„éƒ¨ç½²å°±å¯ä»¥è¯´æ˜¯ ok äº†çš„ï¼Œæ•´ä¸ªé›†ç¾¤çš„ cni éƒ½å¤„äºæ­£å¸¸çŠ¶æ€ï¼Œå…¶ä½™çš„å·¥ä½œè´Ÿè½½ä¹Ÿéƒ½èƒ½å¤Ÿæ­£å¸¸è¿è¡Œäº†ã€‚

å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ Cilium CLIã€‚Cilium CLI å¯ç”¨äºå®‰è£… Ciliumã€æ£€æŸ¥ Cilium å®‰è£…çš„çŠ¶æ€ä»¥åŠå¯ç”¨/ç¦ç”¨å„ç§åŠŸèƒ½ï¼ˆä¾‹å¦‚ clustermeshã€Hubbleï¼‰ã€‚

```bash
CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)

CLI_ARCH=amd64

if [ "$(uname -m)" = "aarch64" ]; then CLI_ARCH=arm64; fi
curl -L --fail --remote-name-all https://ghproxy.com/https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}

sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum

sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin

rm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
```

è¦éªŒè¯ Cilium æ˜¯å¦å·²æ­£ç¡®å®‰è£…ï¼Œæ‚¨å¯ä»¥è¿è¡Œ

```bash
cilium status --wait
```

è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥éªŒè¯æ‚¨çš„é›†ç¾¤æ˜¯å¦å…·æœ‰æ­£ç¡®çš„ç½‘ç»œè¿æ¥ï¼š

```bash
cilium connectivity test
```

æ­å–œï¼æ‚¨æ‹¥æœ‰ä¸€ä¸ªå¸¦æœ‰ Cilium çš„åŠŸèƒ½é½å…¨çš„ Kubernetes é›†ç¾¤ã€‚ğŸ‰

### 7.3 è®¾ç½® Hubble å¯è§‚æµ‹æ€§

Hubble æ˜¯ Cilium çš„å¯è§‚å¯Ÿå±‚ï¼Œå¯ç”¨äºè·å– Kubernetes é›†ç¾¤çš„ç½‘ç»œå’Œå®‰å…¨å±‚çš„é›†ç¾¤èŒƒå›´å†…çš„å¯è§æ€§ã€‚

::: tip
ç¡®è®¤ Cilium å·²æ­£ç¡®å®‰è£…åœ¨æ‚¨çš„ Kubernetes é›†ç¾¤ä¸­ã€‚
:::

åœ¨ Cilium ä¸­å¯ç”¨ Hubble

```bash
cilium hubble enable

cilium status
```

å¯ç”¨ Hubble éœ€è¦åœ¨è¿è¡Œ Cilium çš„æ‰€æœ‰èŠ‚ç‚¹ä¸Šæ‰“å¼€ TCP ç«¯å£ 4244ã€‚è¿™æ˜¯æ­£ç¡®è¿è¡Œæ‰€å¿…éœ€çš„ã€‚

ä¸ºäº†è®¿é—® Hubble æ”¶é›†çš„å¯è§‚æµ‹æ€§æ•°æ®ï¼Œè¯·å®‰è£… Hubble CLIï¼š

```bash
HUBBLE_VERSION=$(curl -s https://ghproxy.com/https://raw.githubusercontent.com/cilium/hubble/master/stable.txt)

HUBBLE_ARCH=amd64

if [ "$(uname -m)" = "aarch64" ]; then HUBBLE_ARCH=arm64; fi
curl -L --fail --remote-name-all https://ghproxy.com/https://github.com/cilium/hubble/releases/download/$HUBBLE_VERSION/hubble-linux-${HUBBLE_ARCH}.tar.gz{,.sha256sum}

sha256sum --check hubble-linux-${HUBBLE_ARCH}.tar.gz.sha256sum

sudo tar xzvfC hubble-linux-${HUBBLE_ARCH}.tar.gz /usr/local/bin

rm hubble-linux-${HUBBLE_ARCH}.tar.gz{,.sha256sum}
```

éªŒè¯ Hubble API è®¿é—®ï¼Œä¸ºäº†è®¿é—® Hubble APIï¼Œè¯·åˆ›å»ºä¸€ä¸ªä»æœ¬åœ°è®¡ç®—æœºè½¬å‘åˆ° Hubble æœåŠ¡çš„ç«¯å£ã€‚è¿™å°†å…è®¸æ‚¨å°† Hubble å®¢æˆ·ç«¯è¿æ¥åˆ°æœ¬åœ°ç«¯å£ 4245 å¹¶è®¿é—® Kubernetes é›†ç¾¤ä¸­çš„ Hubble Relay æœåŠ¡ã€‚æœ‰å…³æ­¤æ–¹æ³•çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·[å‚é˜…ä½¿ç”¨ç«¯å£è½¬å‘è®¿é—®é›†ç¾¤ä¸­çš„åº”ç”¨ç¨‹åº](https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/)ã€‚

```bash
# æ–¹å¼ä¸€ï¼šä½¿ç”¨cilium-cliå·¥å…·å®‰è£…çš„hubbleä¹Ÿå¯ä»¥ä½¿ç”¨ciliumæš´éœ²apiç«¯å£ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯è¯¥å‘½ä»¤é»˜è®¤ä¼šæš´éœ²åˆ°IPV6å’ŒIPV4ç½‘ç»œä¸­ï¼Œå¦‚æœå®¿ä¸»æœºèŠ‚ç‚¹ä¸æ”¯æŒipv6ç½‘ç»œä¼šæŠ¥é”™
cilium hubble port-forward&

# æ–¹å¼äºŒï¼šä½¿ç”¨kubectlçš„port-forwardåŠŸèƒ½æŠŠhubble-relayè¿™ä¸ªæœåŠ¡çš„80ç«¯å£æš´éœ²åˆ°4245ç«¯å£ä¸Š
kubectl port-forward -n kube-system svc/hubble-relay --address 0.0.0.0 4245:80 &
```

ç°åœ¨æ‚¨å¯ä»¥éªŒè¯æ˜¯å¦å¯ä»¥é€šè¿‡å·²å®‰è£…çš„ CLI è®¿é—® Hubble APIï¼š

```bash
hubble status
```

è¾“å‡º

```bash
Healthcheck (via localhost:4245): Ok
Current/Max Flows: 16,380/16,380 (100.00%)
Flows/s: 25.77
Connected Nodes: 4/4
```

æ‚¨è¿˜å¯ä»¥æŸ¥è¯¢æµ API å¹¶æŸ¥æ‰¾æµï¼š

```bash
hubble observe
```

::: tip
å¦‚æœæ‚¨å°†ç«¯å£è½¬å‘åˆ°é™¤ ä¹‹å¤–çš„ç«¯å£ 4245ï¼Œè¯·ç¡®ä¿ä½¿ç”¨ --server æ ‡å¿—æˆ– HUBBLE_SERVER ç¯å¢ƒå˜é‡æ¥è®¾ç½® Hubble æœåŠ¡å™¨åœ°å€ï¼ˆé»˜è®¤å€¼ï¼šlocalhost:4245ï¼‰ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·é€šè¿‡è¿è¡Œæˆ– é…ç½® Hubble CLI æŸ¥çœ‹ Hubble CLI çš„å¸®åŠ©æ¶ˆæ¯ã€‚hubble help statushubble help observehubble config
:::

### 7.4 Service Map & Hubble UI

::: tip
ç¡®è®¤ Cilium å’Œ Hubble å·²æ­£ç¡®å®‰è£…åœ¨ Kubernetes é›†ç¾¤ä¸­ã€‚
:::

é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤å¯ç”¨ Hubble UIï¼š

::: warning
å¦‚æœå·²ä½¿ç”¨ å¯ç”¨ Hubble ï¼Œåˆ™å¿…é¡»å…ˆä½¿ç”¨ æš‚æ—¶ç¦ç”¨ Hubble ã€‚è¿™æ˜¯å› ä¸º Hubble UI æ— æ³•åœ¨è¿è¡Œæ—¶æ·»åŠ ã€‚cilium hubble enable
cilium hubble disable
:::

```bash
cilium hubble disable

cilium hubble enable --ui
```

ä½¿ç”¨ nodeport çš„æ–¹å¼æ¥æš´éœ² hubble-uiï¼Œé¦–å…ˆæˆ‘ä»¬æŸ¥çœ‹åŸæ¥çš„ hubble-ui è¿™ä¸ª svc çš„é…ç½®

```bash
kubectl get svc -n kube-system hubble-ui

# ä¿®æ”¹ type: NodePort
kubectl edit svc -n kube-system hubble-ui

kubectl get svc -n kube-system hubble-ui
NAME        TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
hubble-ui   NodePort   10.18.24.150   <none>        80:30317/TCP   40s
```

è¿™æ—¶å€™æˆ‘ä»¬åœ¨æµè§ˆå™¨ä¸­è®¿é—® http://120.79.229.149:30317/ å°±å¯ä»¥çœ‹åˆ° hubble çš„ ui ç•Œé¢äº†

## 8. é‡ç½®é›†ç¾¤

ä»»æ„ master èŠ‚ç‚¹æ‰§è¡Œä»¥ä¸‹å‘½ä»¤åˆ é™¤èŠ‚ç‚¹

```bash
kubectl delete node free01
kubectl delete node free02
kubectl delete node free03
```

æ‰€æœ‰èŠ‚ç‚¹æ‰§è¡Œä»¥ä¸‹å‘½ä»¤é‡ç½®

```bash
kubeadm reset -f
```
